# -*- coding: utf-8 -*-
"""Fine-tuningBERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_mbGmxlBrZ8TcIqs3rLlIUxR7LdvAMgV
"""

from huggingface_hub import notebook_login

notebook_login()

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install transformers
# !pip install datasets
# !pip install evaluate

from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding
import os

dataset = load_dataset("json", data_files={"train": "/content/treino.jsonl", "test": "/content/teste.jsonl"})

dataset

# Construção de embeddings do texto
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

mapDict = {
    "suporte": 0,
    "venda": 1
}

def transform_labels(example):
    completions = example['completion']

    result = []

    for item in completions:
        numero_label = mapDict[item]

        result.append(numero_label)

    return {"label": result}

def tokenize_function(example):
    return tokenizer(example['prompt'], padding=True, truncation=True)

# Tokenização do input e transformação dos labels
tokenized_datasets = dataset.map(tokenize_function, batched=True)
tokenized_datasets = tokenized_datasets.map(transform_labels, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

from transformers import TrainingArguments

output_dir = "./bert-customer-service-test"

training_args = TrainingArguments(
    output_dir = output_dir,
    num_train_epochs = 3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    weight_decay=0.01,
    logging_dir = "./logs",
    logging_steps = 100,
    eval_strategy = "steps",
    eval_steps = 200,
    save_total_limit = 2,
    save_steps = 200,
    load_best_model_at_end = True,
    metric_for_best_model = "accuracy",
    report_to="none"
)

from transformers import Trainer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)

os.environ['WANDB_DISABLE'] = "true"
os.environ['WANDB_MODE'] = "offline"

import numpy as np
import evaluate

metric = evaluate.load("accuracy")

def compute_metric(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis= -1)
    return metric.compute(predictions=predictions, references=labels)

trainer = Trainer(
    model,
    training_args,
    train_dataset = tokenized_datasets['train'],
    eval_dataset = tokenized_datasets['test'],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metric
)

trainer.train()

trainer.evaluate()

trainer.save_model()

trainer.push_to_hub("luizaugustoliveira/modelservice")

from transformers import pipeline

pipe = pipeline("text-classification", model="luizaugustoliveira/bert-customer-service-test")

pipe("Quero uma SmarTV 55 polegadas")

pipe("Não estou conseguindo fazer login no sistema")